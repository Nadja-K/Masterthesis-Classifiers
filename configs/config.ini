[DATASET]
;DATASET_DATABASE_NAME = ../data/databases/dataset_mixed_small.db
;DATASET_DATABASE_NAME = D:/Neuer Ordner/databases/dataset_empolis_full.db
;DATASET_DATABASE_NAME = ../data/empolis/dataset_empolis_full.db
DATASET_DATABASE_NAME = ../data/empolis/dataset_empolis_full2.db
;EMPOLIS_EVAL_MAPPING_FILE = D:/Neuer Ordner/databases/dataset_empolis_full_synonym_mapping.json
;EMPOLIS_EVAL_MAPPING_FILE = ../data/empolis/dataset_empolis_full_synonym_mapping.json
EMPOLIS_EVAL_MAPPING_FILE = ../data/empolis/dataset_empolis_full2_synonym_mapping.json
;DATASET_DATABASE_NAME = D:/Neuer Ordner/databases/dataset_mixed_small.db
;DATASET_DATABASE_NAME = D:/Neuer Ordner/databases/dataset_mixed_large.db
;DATASET_DATABASE_NAME = D:/Neuer Ordner/databases/dataset_geraete_small.db
;DATASET_DATABASE_NAME = D:/Neuer Ordner/databases/dataset_excellent_onesize.db
;SKIP_TRIVIAL_SAMPLES = True
SKIP_TRIVIAL_SAMPLES = False
SPLIT = val
;SPLIT = test
;SPLIT = train
SPLIT_TABLE_NAME = splits
;SPLIT_TABLE_NAME = splits_4K

[RULECLASSIFIER]
# Default values that are used for all heuristics unless otherwise specified
;MAX_EDIT_DISTANCE_DICTIONARY = 2
MAX_EDIT_DISTANCE_DICTIONARY = 0
PREFIX_LENGTH = 4
COUNT_THRESHOLD = 1
COMPACT_LEVEL = 5

# The max edit distance for the abbreviation heuristics should always be as low as possible
ABBREVIATIONS_MAX_EDIT_DISTANCE_DICTIONARY = 0
# This list was manually extracted from the mixed_large dataset (validation split) and covers some of the most commonly
# used corporate forms
CORPORATE_FORMS_LIST = ["Co", "SA", "NV", "SE", "eG", "AB", "GmbH", "GenmbH", "gGmbH", "mbH", "KG", "eV", "Ltd", "Corp", "Inc", "LLC", "AG", "OHG", "KGaA"]
# A threshold value for the compound splitting. A higher value means the compounds are more likely to be correct.
COMPOUND_SPLITTING_THRESHOLD = 0.1


[ANNOY]
# Valid metrics are: angular, euclidean, manhattan, hamming, dot
ANNOY_METRIC = angular
;ANNOY_METRIC = euclidean
;ANNOY_METRIC = manhattan
;ANNOY_METRIC = hamming
;ANNOY_METRIC = dot
# More trees gives higher precision when querying, only necessary when a new index is created
NUM_TREES = 20
# [Optional] provide a pre-computed index file (Note: annoy can only load index files that are smaller than 2GB)
;ANNOY_INDEX_PATH =
# Directory to store all annoy related data to
ANNOY_OUTPUT_DIR = annoy_data/


[EMBEDDINGCLASSIFIER_TOKENLEVEL]
# Path to a pre-trained embedding model, e.g. a german sent2vec model.
EMBEDDING_MODEL_PATH = ../sent2vec/models/de_model.bin
# Split a word into its compound if it was not found in the embedding model (rn only sent2vec) and try again
;USE_COMPOUND_SPLITTING = False
USE_COMPOUND_SPLITTING = True
# A threshold value for the compound splitting. A higher value means the compounds are more likely to be correct.
COMPOUND_SPLITTING_THRESHOLD = 0.5
;COMPOUND_SPLITTING_THRESHOLD = 0.8
;COMPOUND_SPLITTING_THRESHOLD = 1.0
# If this is set the top NUM_RESULTS per sample will be used for the evaluation
NUM_RESULTS = 1
# The top NUM_RESULTS will be further filtered out by this distance allowance, if this is not set, all NUM_RESULTS
# will be used for the evaluation
;DISTANCE_ALLOWANCE = 0.05


[EMBEDDINGCLASSIFIER_BERT]
;VOCAB_FILE = D:/Neuer Ordner/bert_models/original/vocab.txt
VOCAB_FILE = ../data/empolis/original/vocab.txt
DO_LOWER_CASE = False
BERT_CONFIG_FILE =  ../data/empolis/original/bert_config.json
INIT_CHECKPOINT = ../data/empolis/original/bert_model.ckpt

;INIT_CHECKPOINT = ../data/empolis/finetuned/model.ckpt-4000
;INIT_CHECKPOINT = D:/Neuer Ordner/bert_models/mixed_small/cosine_contrastive_loss/model.ckpt-9000
;INIT_CHECKPOINT = D:/Neuer Ordner/bert_models/mixed_large/cosine_contrastive_loss/model.ckpt-15000
;INIT_CHECKPOINT = D:/Neuer Ordner/bert_models/geraete_small/cosine_contrastive_loss/model.ckpt-9000
;INIT_CHECKPOINT = D:/Neuer Ordner/bert_models/geraete_large/cosine_contrastive_loss/model.ckpt-15000
;INIT_CHECKPOINT = D:/Neuer Ordner/bert_models/excellent_onesize/cosine_contrastive_loss/model.ckpt-9000

# Specify which transformer layer should be used. If multiple are specified the results will be concatenated.
;LAYER_INDEXES = [-1, -11, -12]
LAYER_INDEXES = [-1, -12]
;LAYER_INDEXES = [-1]
USE_ONE_HOT_EMBEDDINGS = False
SEQ_LEN = 256
;BATCH_SIZE = 16
BATCH_SIZE = 30
# If this is set the top NUM_RESULTS per sample will be used for the evaluation
;NUM_RESULTS = 5
# The top NUM_RESULTS will be further filtered out by this distance allowance, if this is not set, all NUM_RESULTS
# will be used for the evaluation
;DISTANCE_ALLOWANCE = 0.05


[EVALUATION]
# Two evaluation modes are supported, 'samples' and 'mentions'. The first one takes all SAMPLES of the dataset into
# consideration. The second one calculated an average score per MENTION to ensure that duplicate mention samples
# do not affect the final score.
;MODE = mentions
MODE = samples
