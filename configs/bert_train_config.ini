[TRAINING]
VOCAB_FILE = ../bert/models/vocab.txt
BERT_CONFIG_FILE = ../bert/models/bert_config.json
INIT_CHECKPOINT = ../bert/models/bert_model.ckpt
OUTPUT_DIR = ../bert/models/finetuned_mixed_small

DO_LOWER_CASE = True

LAYER_INDEXES = [-1]
SEQ_LEN = 256
BATCH_SIZE = 20

WARUMUP_PROPORTION = 0.0
NUM_TRAIN_EPOCHS = 100.0
LEARNING_RATE = 2e-6
MARGIN = 2.0

# Every time a checkpoint is saved the evaluation will be performed.
SAVE_CHECKPOINTS_STEPS = 5
SUMMARY_STEPS = 1

[EVALUATION]
# The number of batch-steps the evaluation is supposed to run. The eval_loss is the average over all sampels and runs.
STEPS_PER_EVAL_ITER = 10

[DATASET]
;DATASET_DATABASE_NAME = ../data/databases/dataset_tree.db
DATASET_DATABASE_NAME = ../data/databases/dataset_mixed_small.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_mixed_large.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_geraete_small.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_geraete_large.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_excellent_onesize.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_full_wikipedia.db
;SKIP_TRIVIAL_SAMPLES = True
SKIP_TRIVIAL_SAMPLES = False
SPLIT = train
SPLIT_TABLE_NAME = splits
;SPLIT_TABLE_NAME = splits_10K