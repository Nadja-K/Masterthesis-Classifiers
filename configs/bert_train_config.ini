[TRAINING]
DO_LOWER_CASE = False

;VOCAB_FILE = ../bert/models/german_pretrained/vocab.txt
;BERT_CONFIG_FILE = ../bert/models/german_pretrained/bert_config.json
;INIT_CHECKPOINT = ../bert/models/german_pretrained/bert-base-german-cased.ckpt

;VOCAB_FILE = ../bert/models/vocab.txt
;BERT_CONFIG_FILE = ../bert/models/bert_config.json
;INIT_CHECKPOINT = ../bert/models/bert_model.ckpt

VOCAB_FILE = ../data/empolis/original/vocab.txt
BERT_CONFIG_FILE =  ../data/empolis/original/bert_config.json
INIT_CHECKPOINT = ../data/empolis/original/bert_model.ckpt

;OUTPUT_DIR = ../bert/models/finetuned1/mixed_small/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned2/mixed_small/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned1/mixed_small/cosine_cross_entropy_loss
;OUTPUT_DIR = ../bert/models/finetuned2/mixed_small/cosine_cross_entropy_loss
;OUTPUT_DIR = ../bert/models/finetuned1/mixed_small/improved_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned2/mixed_small/improved_contrastive_loss

;OUTPUT_DIR = ../bert/models/finetuned3/mixed_small/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned3/geraete_small/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned3/mixed_large/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned3/geraete_large/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned3/excellent_onesize/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned3/full_wikipedia/cosine_contrastive_loss

;OUTPUT_DIR = ../bert/models/finetuned4/mixed_small/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned4/mixed_large/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned4/geraete_small/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned4/geraete_large/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned4/excellent_onesize/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/finetuned4/full_wikipedia/cosine_contrastive_loss

;OUTPUT_DIR = ../bert/models/german_finetuned/geraete_large/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/german_finetuned/mixed_large/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/german_finetuned/mixed_small/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/german_finetuned/geraete_small/cosine_contrastive_loss
;OUTPUT_DIR = ../bert/models/german_finetuned/excellent_onesize/cosine_contrastive_loss

;OUTPUT_DIR = ../bert/models/finetuned5/output_layer/mixed_small/one_twelve
;OUTPUT_DIR = ../bert/models/finetuned5/loss_function/mixed_small/euclidean_contrastive_loss
;OUTPUT_DIR = ../bert/models/delete_this/

OUTPUT_DIR = ../data/empolis/finetuned/


;LAYER_INDEXES = [-1]
LAYER_INDEXES = [-1, -12]
SEQ_LEN = 256
;SEQ_LEN = 128
;BATCH_SIZE = 30
;BATCH_SIZE = 20
BATCH_SIZE = 1

WARUMUP_PROPORTION = 0.0
LEARNING_RATE = 2e-6
NUM_TRAIN_EPOCHS = 20.0
# If this is enabled, NUM_TRAIN_EPOCHS will be ignored.
;NUM_TRAIN_STEPS = 15000
;NUM_TRAIN_STEPS = 9000
NUM_TRAIN_STEPS = 6000


# Choose one out of: cosine_contrastive, cosine_cross_entropy, improved_contrastive, euclidean_contrastive
LOSS = cosine_contrastive
;LOSS = euclidean_contrastive
# Only for cosine_contrastive and improved_contrastive
MARGIN = 2.0
# Only for improved_contrastive
BETA = 1.0

# Every time a checkpoint is saved the evaluation will be performed.
SAVE_CHECKPOINTS_STEPS = 250
SUMMARY_STEPS = 1

[EVALUATION]
# The number of batch-steps the evaluation is supposed to run. The eval_loss is the average over all sampels and runs.
STEPS_PER_EVAL_ITER = 100

[DATASET]
;DATASET_DATABASE_NAME = ../data/databases/dataset_tree.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_mixed_small.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_mixed_large.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_geraete_small.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_geraete_large.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_excellent_onesize.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_full_wikipedia.db
DATASET_DATABASE_NAME = ../data/empolis/dataset_empolis_full2.db
;SKIP_TRIVIAL_SAMPLES = True
SKIP_TRIVIAL_SAMPLES = False
SPLIT = train
SPLIT_TABLE_NAME = splits
;SPLIT_TABLE_NAME = splits_10K

# Generate x positive and x negative pairwise sentence samples per entity resulting in 2*x pairs per entity if possible
NUM_QUERY_SENTENCES_PER_ENTITY = 4