[DATASET]
;DATASET_DATABASE_NAME = ../data/databases/dataset_test.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_test_midsize.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_geraete_large_test.db
DATASET_DATABASE_NAME = ../data/databases/dataset_mixed_small_test.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_mixed_large.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_geraete_small.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_geraete_large.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_excellent_onesize_test.db
;DATASET_DATABASE_NAME = ../data/databases/dataset_full_wikipedia.db
SKIP_TRIVIAL_SAMPLES = True
;SKIP_TRIVIAL_SAMPLES = False
SPLIT = val
SPLIT_TABLE_NAME = splits
;SPLIT_TABLE_NAME = splits_10K

[RULECLASSIFIER]
# Default values that are used for all heuristics unless otherwise specified
MAX_EDIT_DISTANCE_DICTIONARY = 2
PREFIX_LENGTH = 4
COUNT_THRESHOLD = 1
COMPACT_LEVEL = 5

# The max edit distance for the abbreviation heuristics should always be as low as possible
ABBREVIATIONS_MAX_EDIT_DISTANCE_DICTIONARY = 0
# This list was manually extracted from the mixed_large dataset (validation split) and covers some of the most commonly
# used corporate forms
CORPORATE_FORMS_LIST = ["Co", "SA", "NV", "SE", "eG", "AB", "GmbH", "GenmbH", "gGmbH", "mbH", "KG", "eV", "Ltd", "Corp", "Inc", "LLC", "AG", "OHG", "KGaA"]


[ANNOY]
# Valid metrics are: angular, euclidean, manhattan, hamming, dot
ANNOY_METRIC = angular
;ANNOY_METRIC = euclidean
;ANNOY_METRIC = manhattan
;ANNOY_METRIC = hamming
;ANNOY_METRIC = dot
# More trees gives higher precision when querying, only necessary when a new index is created
NUM_TREES = 20
# [Optional] provide a pre-computed index file (Note: annoy can only load index files that are smaller than 2GB)
;ANNOY_INDEX_PATH =
# Directory to store all annoy related data to
ANNOY_OUTPUT_DIR = annoy_data/


[EMBEDDINGCLASSIFIER_TOKENLEVEL]
# Path to a pre-trained embedding model, e.g. a german sent2vec model.
EMBEDDING_MODEL_PATH = ../sent2vec/models/de_model.bin
# Split a word into its compound if it was not found in the embedding model (rn only sent2vec) and try again
USE_COMPOUND_SPLITTING = False
;USE_COMPOUND_SPLITTING = True
# A threshold value for the compound splitting. A higher value means the compounds are more likely to be correct.
COMPOUND_SPLITTING_THRESHOLD = 0.5
;COMPOUND_SPLITTING_THRESHOLD = 0.8
;COMPOUND_SPLITTING_THRESHOLD = 1.0
# If this is set the top NUM_RESULTS per sample will be used for the evaluation
;NUM_RESULTS = 1
# The top NUM_RESULTS will be further filtered out by this distance allowance, if this is not set, all NUM_RESULTS
# will be used for the evaluation
;DISTANCE_ALLOWANCE = 0.05


[EMBEDDINGCLASSIFIER_BERT]
VOCAB_FILE = ../bert/models/vocab.txt
DO_LOWER_CASE = True
BERT_CONFIG_FILE = ../bert/models/bert_config.json
INIT_CHECKPOINT = ../bert/models/bert_model.ckpt
# Specify which transformer layer should be used. If multiple are specified the results will be concatenated.
LAYER_INDEXES = [-2]
USE_ONE_HOT_EMBEDDINGS = False
SEQ_LEN = 256
BATCH_SIZE = 128
# If this is set the top NUM_RESULTS per sample will be used for the evaluation
;NUM_RESULTS = 2
# The top NUM_RESULTS will be further filtered out by this distance allowance, if this is not set, all NUM_RESULTS
# will be used for the evaluation
;DISTANCE_ALLOWANCE = 0.05


[EVALUATION]
# Two evaluation modes are supported, 'samples' and 'mentions'. The first one takes all SAMPLES of the dataset into
# consideration. The second one calculated an average score per MENTION to ensure that duplicate mention samples
# do not affect the final score.
;MODE = mentions
MODE = samples